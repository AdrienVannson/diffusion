{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import math\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Mount Google Drive if executed on Google Colab\n",
    "try:\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount('/content/gdrive/')\n",
    "    sys.path.append('/content/gdrive/MyDrive/GenAI')\n",
    "\n",
    "    ROOT_PATH = '/content/gdrive/MyDrive/GenAI/'\n",
    "    onColab = True\n",
    "except:\n",
    "    print(\"Not running on Google Colab\")\n",
    "    onColab = False\n",
    "    ROOT_PATH = './'\n",
    "\n",
    "from images import show_grid\n",
    "from model import Model, PositionalEmbedding\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_STEPS = 1000 - 1\n",
    "LEARNING_RATE = 1e-4\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "DATASET = 'hands32x32' # 'cifar10', 'hands32x32', 'hands64x64', 'hands128x128'\n",
    "\n",
    "NB_EPOCHS = {\n",
    "    'cifar10': 1000,\n",
    "    'hands32x32': 50,\n",
    "}[DATASET]\n",
    "\n",
    "SAVE_EVERY = 10\n",
    "EXPERIMENT_NAME = 'hands32x32'\n",
    "\n",
    "if device == 'cpu':\n",
    "    NB_EPOCHS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the output folder\n",
    "OUTPUT_PATH = ROOT_PATH + f'output/{EXPERIMENT_NAME}/'\n",
    "os.system(f'mkdir -p {OUTPUT_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == 'cifar10':\n",
    "    # Download the dataset\n",
    "    cifar10 = torchvision.datasets.CIFAR10(root='./data', train=True, download=True)\n",
    "\n",
    "    print(\"Classes:\", *cifar10.classes)\n",
    "\n",
    "    # Extract a category of images\n",
    "    real_images = cifar10.data[ [i for i, t in enumerate(cifar10.targets) if t == cifar10.classes.index('automobile')] ]\n",
    "\n",
    "elif DATASET in ['hands32x32', 'hands64x64', 'hands128x128']:\n",
    "    s = int(DATASET.split('x')[1])\n",
    "\n",
    "    if os.path.isfile(ROOT_PATH + f'data/hands/{str(s)}x{str(s)}.npy'):\n",
    "        real_images = np.load(ROOT_PATH + f'data/hands/{str(s)}x{str(s)}.npy')\n",
    "    else:\n",
    "        folder = f'data/hands/{str(s)}x{str(s)}/'\n",
    "        files = os.listdir(folder)\n",
    "\n",
    "        real_images = np.empty((len(files), s, s, 3), dtype=np.uint8)\n",
    "\n",
    "        for i, f in enumerate(files):\n",
    "            img = np.array(Image.open(os.path.join(folder, f)))\n",
    "            real_images[i] = img\n",
    "        \n",
    "        np.save(f'data/hands/{str(s)}x{str(s)}.npy', real_images)\n",
    "\n",
    "else:\n",
    "    print('Error: dataset does not exist')\n",
    "\n",
    "real_images = real_images / (255 / 2) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow testing without GPU\n",
    "if not onColab:\n",
    "    real_images = real_images[:2]\n",
    "\n",
    "# Data augmentation: rotate and flip the images\n",
    "rotated = []\n",
    "for img in real_images:\n",
    "    rotated.append(img)\n",
    "    rotated.append(np.rot90(img, 1, (0, 1)))\n",
    "    rotated.append(np.rot90(img, 2, (0, 1)))\n",
    "    rotated.append(np.rot90(img, 3, (0, 1)))\n",
    "\n",
    "    img = np.fliplr(img)\n",
    "\n",
    "    rotated.append(img)\n",
    "    rotated.append(np.rot90(img, 1, (0, 1)))\n",
    "    rotated.append(np.rot90(img, 2, (0, 1)))\n",
    "    rotated.append(np.rot90(img, 3, (0, 1)))\n",
    "\n",
    "real_images = rotated\n",
    "\n",
    "# Use floats\n",
    "real_images = np.array(real_images, dtype=np.float32)\n",
    "\n",
    "# Put the channel at the end\n",
    "real_images = np.swapaxes(real_images, 1, 3)\n",
    "\n",
    "show_grid(real_images[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_beta(step):\n",
    "    return 0.0001 + (step / NB_STEPS) * 0.02\n",
    "\n",
    "# Adds one or several times noise to an image\n",
    "def add_noise(img, first_step, last_step = -1):\n",
    "    if last_step == -1:\n",
    "        last_step = first_step + 1\n",
    "\n",
    "    alpha = 1\n",
    "    for k in range(first_step, last_step):\n",
    "        alpha *= (1 - get_beta(k))\n",
    "\n",
    "    return math.sqrt(alpha) * img + np.random.normal(scale=math.sqrt(1 - alpha), size=img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add noise to an image progressively\n",
    "noisy = [real_images[0]]\n",
    "\n",
    "for k in range(NB_STEPS):\n",
    "    noisy.append(add_noise(noisy[-1], k))\n",
    "\n",
    "show_grid(np.array(noisy[::20]))\n",
    "\n",
    "del noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add noise from the beginning each time\n",
    "noisy = [real_images[0]]\n",
    "\n",
    "for k in range(NB_STEPS):\n",
    "    noisy.append(add_noise(noisy[0], 0, k + 1))\n",
    "\n",
    "show_grid(np.array(noisy[::20]))\n",
    "\n",
    "del noisy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_emb = PositionalEmbedding(NB_STEPS, 64)()\n",
    "\n",
    "plt.figure(figsize=(8, 2.5))\n",
    "plt.pcolormesh(pos_emb, cmap='viridis')\n",
    "plt.xlabel(\"Embedding dimension\")\n",
    "plt.ylabel(\"Time\")\n",
    "plt.title(\"Positional Encoding\")\n",
    "plt.colorbar(label='Embedding value')\n",
    "plt.show()\n",
    "\n",
    "pos_emb = pos_emb.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(32).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=4, min_lr=1e-6)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# pin_memory improves performance on GPU\n",
    "data_loader = torch.utils.data.DataLoader(real_images, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image():\n",
    "    model.eval()\n",
    "\n",
    "    img = torch.normal(mean=torch.zeros(1, 3, 32, 32), std=torch.ones(1, 3, 32, 32)).to(device)\n",
    "\n",
    "    hist = [] # The tensors are on the CPU\n",
    "\n",
    "    for k in tqdm(range(NB_STEPS-1, -1, -1)):\n",
    "        with torch.no_grad():\n",
    "            #pred = model(img, pos_emb[k:k+1, :])\n",
    "            pred = 0.98 * img\n",
    "\n",
    "        alpha = 1\n",
    "        for i in range(k+1):\n",
    "            alpha *= (1 - get_beta(i))\n",
    "        \n",
    "        noise = torch.normal(mean=torch.zeros(1, 3, 32, 32), std=torch.ones(1, 3, 32, 32)).to(device)\n",
    "\n",
    "        img = (img - get_beta(k) / math.sqrt(1 - alpha) * pred) / math.sqrt(1 - get_beta(k)) + \\\n",
    "            math.sqrt(get_beta(k)) * noise\n",
    "\n",
    "        if k % ((NB_STEPS+1) // 40) == 0:\n",
    "            hist.append(img.detach().cpu())\n",
    "\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "\n",
    "loss_hist, lr_hist = [], []\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "for epoch in (pbar := tqdm(range(NB_EPOCHS))):\n",
    "    epoch_str = str(epoch).zfill(5)\n",
    "\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    lr_hist.append(lr)\n",
    "    pbar.set_description(f\"lr = {lr}\")\n",
    "\n",
    "    sum_loss = 0\n",
    "\n",
    "    for batch, images in enumerate(data_loader):\n",
    "        images = images.to(device)\n",
    "\n",
    "        # Generate noisy images\n",
    "        err = torch.normal(mean=torch.zeros(images.shape), std=torch.ones(images.shape)).to(device)\n",
    "\n",
    "        steps = torch.randint(0, NB_STEPS, size=(len(images), 1, 1, 1))\n",
    "\n",
    "        alphas = torch.ones(steps.shape)\n",
    "        for k in range(NB_STEPS):\n",
    "            alphas = (steps > 0) * alphas * (1 - get_beta(k)) + (steps <= 0) * alphas\n",
    "            steps -= 1\n",
    "        alphas = alphas.to(device).repeat(1, *images.shape[1:])\n",
    "\n",
    "        noisy_images = torch.sqrt(alphas) * images + torch.sqrt(1 - alphas) * err\n",
    "\n",
    "        # Train the model on them\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "            pred_err = model(noisy_images, pos_emb[steps.squeeze(1).squeeze(1).squeeze(1)])\n",
    "            loss = loss_fn(pred_err, err)\n",
    "            sum_loss += loss.item()\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        del images, err, steps, alphas, noisy_images\n",
    "\n",
    "    # Reduce the learning rate if needed\n",
    "    scheduler.step(sum_loss)\n",
    "    loss_hist.append(sum_loss)\n",
    "\n",
    "    if epoch % SAVE_EVERY == SAVE_EVERY - 1:\n",
    "        # Create an output folder\n",
    "        os.system(f'mkdir -p {OUTPUT_PATH}{epoch_str}')\n",
    "\n",
    "        # Save the model\n",
    "        torch.save(model.state_dict(), OUTPUT_PATH + epoch_str + '/model')\n",
    "\n",
    "        # Generate a few images\n",
    "        generated_images = []\n",
    "\n",
    "        for i in range(12):\n",
    "            hist = generate_image()\n",
    "            show_grid(np.array([img.numpy().squeeze(0) for img in hist]), 10, f'{OUTPUT_PATH}{epoch_str}/hist-' + str(i).zfill(2))\n",
    "            np.save(f'{OUTPUT_PATH}{epoch_str}/{str(i).zfill(2)}.npy', hist[-1])\n",
    "            generated_images.append(hist[-1])\n",
    "\n",
    "        show_grid(np.array([img.numpy().squeeze(0) for img in generated_images]), 4, f'{OUTPUT_PATH}{epoch_str}/all')\n",
    "\n",
    "        with open(OUTPUT_PATH + 'metrics', 'w') as f:\n",
    "            f.write(str(loss_hist) + '\\n')\n",
    "            f.write(str(lr_hist) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(loss_hist, label=\"Train loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(\"00079\", map_location=torch.device('cpu')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epfl-dlb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
